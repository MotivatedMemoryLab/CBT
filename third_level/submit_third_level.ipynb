{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Job to Condor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import CBT_thirdlevel\n",
    "import condor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER VARIABLES ####################\n",
    "EXP_DIR = '/Volumes/adcock_lab/main/studies/CBT.01'\n",
    "subject_list_fname = 'CBT_subjs.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE CONDOR CLUSTER SUBMIT JOB #########################\n",
    "myJob = condor.Job()\n",
    "logDir = os.path.join(EXP_DIR, 'scripts/condor_logs')\n",
    "myJob.setUniverse('vanilla')                                \n",
    "myJob.setOutput(os.path.join(logDir, 'output.txt'))\n",
    "myJob.setError(os.path.join(logDir, 'thirdlevel_error.txt'))    \n",
    "myJob.setLog(os.path.join(logDir, 'log.txt'))            \n",
    "myJob._generateSubmitString()\n",
    "##########################################################\n",
    "\n",
    "\n",
    "# BEGIN SCRIPT ######################\n",
    "subject_list = os.path.join(EXP_DIR, 'scripts/analysis_scripts/subject_lists', subject_list_fname)\n",
    "SUBJS = np.genfromtxt(subject_list, dtype='string')\n",
    "#SUBJS = ['15141']\n",
    "\n",
    "\n",
    "#### STANDARD JOBS\n",
    "TRAIN_standard_copes = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "for cope in TRAIN_standard_copes:\n",
    "    this_job = CBT_thirdlevel.make_FSF_file('standard_with_feedback_2', 'TRAIN', cope)\n",
    "    myJob.queue(this_job)\n",
    "\n",
    "\n",
    "#### Last 15 seconds (of the trial) JOBS\n",
    "#TRAIN_last_15_seconds_copes = [1,2,3,4,5,6,7]\n",
    "#for cope in TRAIN_last_15_seconds_copes:\n",
    "#    this_job = CBT_thirdlevel.make_FSF_file('last_15_seconds', 'TRAIN', cope)\n",
    "#    myJob.queue(this_job)\n",
    "\n",
    "\n",
    "# ### THERM JOBS\n",
    "# TRAIN_THERM_copes = [1,2,3,4]\n",
    "# for cope in TRAIN_THERM_copes:\n",
    "#     this_job = SRM_thirdlevel.make_FSF_file('THERM_model', 'TRAIN', cope)\n",
    "#     myJob.queue(this_job)\n",
    "\n",
    "\n",
    "### PPI JOBS\n",
    "#TEST_PPI_copes = [1,2,3,4]\n",
    "#TRAIN_PPI_copes = [1,2,3,4]\n",
    "\n",
    "#for model in ['PPI_NAc_spheres']: #, 'PPI_prob_VTA_atlas_2mm']:\n",
    "    # for cope in TEST_PPI_copes:\n",
    "    #     this_job = SRM_thirdlevel.make_FSF_file(model, 'TEST', cope)\n",
    "    #     myJob.queue(this_job)\n",
    "    \n",
    "#    for cope in TRAIN_PPI_copes:\n",
    "#        this_job = SRM_thirdlevel.make_FSF_file(model, 'TRAIN', cope)\n",
    "#        myJob.queue(this_job)\n",
    "\n",
    "\n",
    "\n",
    "myJob.saveSubmitFile(os.path.join(logDir, 'thirdlevelSubmit.txt'))\n",
    "myJob.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
